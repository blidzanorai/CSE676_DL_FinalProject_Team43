{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DjNkDpraoBlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d580fb6-1f4a-495f-debf-c7decd4cc032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "# Install the kaggle library\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "YPGQ-GRdoE6u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the user to upload the kaggle.json file\n",
        "print(\"Please upload your kaggle.json file\")\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "KZfEotcDoE9D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "90e2989c-c642-44cf-da1d-5705a0d28174"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your kaggle.json file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-82f7c8bc-3278-4021-bf39-007564d5f6c4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-82f7c8bc-3278-4021-bf39-007564d5f6c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"blidzanorai\",\"key\":\"cb18b4d5f7d0813dfa9911a21f99246b\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the kaggle directory and permissions\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "E1NMAlUaoE_q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from kaggle\n",
        "print(\"Downloading the dataset\")\n",
        "!kaggle datasets download -d ikrbasak/sep-28k"
      ],
      "metadata": {
        "id": "f5nC1aM3oFCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f7ebeb-c3e1-46fb-f1f4-3a5f202418b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the dataset\n",
            "Dataset URL: https://www.kaggle.com/datasets/ikrbasak/sep-28k\n",
            "License(s): Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n",
            "Downloading sep-28k.zip to /content\n",
            " 99% 2.14G/2.17G [00:18<00:00, 221MB/s]\n",
            "100% 2.17G/2.17G [00:18<00:00, 125MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the downloaded file\n",
        "print(\"Unzipping the file\")\n",
        "!unzip -q sep-28k.zip"
      ],
      "metadata": {
        "id": "wZ2B3ALooFE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2bc3b5-4e90-4b34-cffe-401e9696e236"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping the file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episodes_file = 'SEP-28k_episodes.csv'\n",
        "labels_file = 'SEP-28k_labels.csv'"
      ],
      "metadata": {
        "id": "cMAfyU8toFHi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes_df = pd.read_csv(episodes_file)\n",
        "labels_df = pd.read_csv(labels_file)"
      ],
      "metadata": {
        "id": "uRcSPzrQoFKW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Information for the Episodes DataFrame\n",
        "print(\"Episodes DataFrame Info\")\n",
        "print(episodes_df.head())\n",
        "print(\"\\nBasic Information:\")\n",
        "episodes_df.info()"
      ],
      "metadata": {
        "id": "VhT_xiG3oFMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78990800-9a9c-46ff-8990-7c0989eaa487"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episodes DataFrame Info\n",
            "  He_Stutters_Podcast_–_Make_Room_For_The_Stuttering  \\\n",
            "0  He_Stutters_Podcast_–_Make_Room_For_The_Stutte...   \n",
            "1  He_Stutters_Podcast_–_Make_Room_For_The_Stutte...   \n",
            "2  He_Stutters_Podcast_–_Make_Room_For_The_Stutte...   \n",
            "3  He_Stutters_Podcast_–_Make_Room_For_The_Stutte...   \n",
            "4  He_Stutters_Podcast_–_Make_Room_For_The_Stutte...   \n",
            "\n",
            "    episode-208-with-kelsey-h  \\\n",
            "0   episode-208-with-kelsey-h   \n",
            "1   episode-208-with-kelsey-h   \n",
            "2   episode-208-with-kelsey-h   \n",
            "3   episode-208-with-kelsey-h   \n",
            "4   episode-208-with-kelsey-h   \n",
            "\n",
            "   https://stutterrockstar.files.wordpress.com/2011/05/male-episode-1-with-alan1.mp3  \\\n",
            "0   https://stutterrockstar.files.wordpress.com/2...                                   \n",
            "1   https://stutterrockstar.files.wordpress.com/2...                                   \n",
            "2   https://stutterrockstar.files.wordpress.com/2...                                   \n",
            "3   https://stutterrockstar.files.wordpress.com/2...                                   \n",
            "4   https://stutterrockstar.files.wordpress.com/2...                                   \n",
            "\n",
            "    HeStutters   0  \n",
            "0   HeStutters   1  \n",
            "1   HeStutters   2  \n",
            "2   HeStutters   3  \n",
            "3   HeStutters   4  \n",
            "4   HeStutters   5  \n",
            "\n",
            "Basic Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 384 entries, 0 to 383\n",
            "Data columns (total 5 columns):\n",
            " #   Column                                                                              Non-Null Count  Dtype \n",
            "---  ------                                                                              --------------  ----- \n",
            " 0   He_Stutters_Podcast_–_Make_Room_For_The_Stuttering                                  384 non-null    object\n",
            " 1    episode-208-with-kelsey-h                                                          384 non-null    object\n",
            " 2    https://stutterrockstar.files.wordpress.com/2011/05/male-episode-1-with-alan1.mp3  384 non-null    object\n",
            " 3    HeStutters                                                                         384 non-null    object\n",
            " 4    0                                                                                  384 non-null    int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 15.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Information for the Labels DataFrame\n",
        "print(\"\\nLabels DataFrame Info\")\n",
        "print(labels_df.head())\n",
        "print(\"\\nBasic Information:\")\n",
        "labels_df.info()"
      ],
      "metadata": {
        "id": "qHD0sUcHoFO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0210946c-6a6e-4c19-fa4a-4f2c0e7d30a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Labels DataFrame Info\n",
            "         Show  EpId  ClipId     Start      Stop  Unsure  PoorAudioQuality  \\\n",
            "0  HeStutters     0       0  31900320  31948320       0                 0   \n",
            "1  HeStutters     0       1  31977120  32025120       0                 0   \n",
            "2  HeStutters     0       2  34809760  34857760       0                 0   \n",
            "3  HeStutters     0       3  35200640  35248640       0                 0   \n",
            "4  HeStutters     0       4  35721920  35769920       0                 0   \n",
            "\n",
            "   Prolongation  Block  SoundRep  WordRep  DifficultToUnderstand  \\\n",
            "0             0      0         0        0                      0   \n",
            "1             0      0         0        0                      0   \n",
            "2             0      0         0        0                      0   \n",
            "3             1      0         0        0                      0   \n",
            "4             0      0         0        0                      0   \n",
            "\n",
            "   Interjection  NoStutteredWords  NaturalPause  Music  NoSpeech  \n",
            "0             0                 3             1      0         0  \n",
            "1             0                 3             1      0         0  \n",
            "2             0                 3             0      0         0  \n",
            "3             0                 2             0      0         0  \n",
            "4             0                 3             0      0         0  \n",
            "\n",
            "Basic Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28177 entries, 0 to 28176\n",
            "Data columns (total 17 columns):\n",
            " #   Column                 Non-Null Count  Dtype \n",
            "---  ------                 --------------  ----- \n",
            " 0   Show                   28177 non-null  object\n",
            " 1   EpId                   28177 non-null  int64 \n",
            " 2   ClipId                 28177 non-null  int64 \n",
            " 3   Start                  28177 non-null  int64 \n",
            " 4   Stop                   28177 non-null  int64 \n",
            " 5   Unsure                 28177 non-null  int64 \n",
            " 6   PoorAudioQuality       28177 non-null  int64 \n",
            " 7   Prolongation           28177 non-null  int64 \n",
            " 8   Block                  28177 non-null  int64 \n",
            " 9   SoundRep               28177 non-null  int64 \n",
            " 10  WordRep                28177 non-null  int64 \n",
            " 11  DifficultToUnderstand  28177 non-null  int64 \n",
            " 12  Interjection           28177 non-null  int64 \n",
            " 13  NoStutteredWords       28177 non-null  int64 \n",
            " 14  NaturalPause           28177 non-null  int64 \n",
            " 15  Music                  28177 non-null  int64 \n",
            " 16  NoSpeech               28177 non-null  int64 \n",
            "dtypes: int64(16), object(1)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load, Combine, and Process Data\n",
        "print(\"Loading and combining datasets\")\n",
        "clips_dir = 'clips/stuttering-clips/clips'\n",
        "sep_labels_df = pd.read_csv('SEP-28k_labels.csv')\n",
        "fluency_labels_df = pd.read_csv('fluencybank_labels.csv')\n",
        "combined_df = pd.concat([sep_labels_df, fluency_labels_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "W8Sz6pAwoFSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b2c2a5-2292-4a16-ddbe-ab6601f8296c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and combining datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Processing labels and cleaning data\")\n",
        "stutter_columns = ['Prolongation', 'Block', 'SoundRep', 'WordRep', 'Interjection']\n",
        "all_event_columns = stutter_columns + ['NoStutteredWords']\n",
        "combined_df['label'] = combined_df[all_event_columns].idxmax(axis=1)\n",
        "\n",
        "clean_df = combined_df[(combined_df['PoorAudioQuality'] == 0) & (combined_df['Music'] == 0) & (combined_df['NoSpeech'] == 0)].copy()"
      ],
      "metadata": {
        "id": "tmtvtPcHoFcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae93041-f61f-4164-9d29-591b3920e471"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing labels and cleaning data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_correct_path(row):\n",
        "    filename = f\"{row['Show']}_{row['EpId']}_{row['ClipId']}.wav\"\n",
        "    return os.path.join(clips_dir, filename)"
      ],
      "metadata": {
        "id": "5DsG41C0oFfe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df['file_path'] = clean_df.apply(generate_correct_path, axis=1)\n",
        "final_df = clean_df[clean_df['file_path'].apply(os.path.exists)].copy()\n",
        "print(f\"Using {len(final_df)} clips with existing audio files\")"
      ],
      "metadata": {
        "id": "tonQuUm-o4Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d811ab-5cbf-4e08-e1da-db81c4bf926a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 26098 clips with existing audio files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "final_df['encoded_label'] = label_encoder.fit_transform(final_df['label'])"
      ],
      "metadata": {
        "id": "siB_PdRDqRHY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Prepare Data for PyTorch\n",
        "print(\"Splitting data\")\n",
        "X = final_df['file_path'].values\n",
        "y = final_df['encoded_label'].values\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "X_train_paths, X_val_paths, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "02eZgjdwqRJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447b8b1a-8f02-4c82-817f-abaf6fce32ea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create a PyTorch Dataset\n",
        "class StutteringDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, n_mels=128, max_pad_len=188):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.n_mels = n_mels\n",
        "        self.max_pad_len = max_pad_len\n",
        "        self.sr = 16000\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        audio, _ = librosa.load(file_path, sr=self.sr)\n",
        "        if len(audio) == 0:\n",
        "            return torch.zeros((1, self.n_mels, self.max_pad_len), dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
        "        mel = librosa.feature.melspectrogram(y=audio, sr=self.sr, n_mels=self.n_mels)\n",
        "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "        if mel_db.shape[1] > self.max_pad_len:\n",
        "            mel_db = mel_db[:, :self.max_pad_len]\n",
        "        else:\n",
        "            pad_width = self.max_pad_len - mel_db.shape[1]\n",
        "            mel_db = np.pad(mel_db, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        mel_db = np.expand_dims(mel_db, axis=0)\n",
        "        return torch.tensor(mel_db, dtype=torch.float32), torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "J2HkZZbwqRMq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = StutteringDataset(X_train_paths, y_train)\n",
        "val_dataset = StutteringDataset(X_val_paths, y_val)\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "aAiLPV7-qRPm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define a Dynamic CNN Model\n",
        "class StutteringCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(StutteringCNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=(3, 3)), nn.ReLU(), nn.MaxPool2d(kernel_size=(2, 2)),\n",
        "            nn.Conv2d(32, 64, kernel_size=(3, 3)), nn.ReLU(), nn.MaxPool2d(kernel_size=(2, 2)))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.LazyLinear(128), nn.ReLU(), nn.Dropout(0.5), nn.Linear(128, num_classes))\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0vJckqn3qRTB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Training Loop\n",
        "print(\"Starting training\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "print(\"Calculating class weights for the loss function\")\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "model = StutteringCNN(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs = 10\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {epoch_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "\n",
        "    if epoch_val_loss < best_val_loss:\n",
        "        best_val_loss = epoch_val_loss\n",
        "        torch.save(model.state_dict(), 'best_model_weights.pth')\n",
        "        print(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete\")"
      ],
      "metadata": {
        "id": "YyayfmDro4b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a20ecdc-3fa8-4ac0-e6f7-2cab4cb3e1f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training\n",
            "Using device: cuda\n",
            "Calculating class weights for the loss function\n",
            "Epoch 1/10, Train Loss: 2.6111, Train Acc: 19.24%, Val Loss: 1.7919, Val Acc: 44.08%\n",
            "New best model saved with validation loss: 1.7919\n",
            "Epoch 2/10, Train Loss: 1.7918, Train Acc: 26.29%, Val Loss: 1.7880, Val Acc: 43.60%\n",
            "New best model saved with validation loss: 1.7880\n",
            "Epoch 3/10, Train Loss: 1.7920, Train Acc: 33.40%, Val Loss: 1.7905, Val Acc: 35.73%\n",
            "Epoch 4/10, Train Loss: 1.7900, Train Acc: 30.10%, Val Loss: 1.7903, Val Acc: 37.91%\n",
            "Epoch 5/10, Train Loss: 1.7898, Train Acc: 26.14%, Val Loss: 1.7915, Val Acc: 44.58%\n",
            "Epoch 6/10, Train Loss: 1.7880, Train Acc: 33.07%, Val Loss: 1.7890, Val Acc: 14.35%\n",
            "Epoch 7/10, Train Loss: 1.7879, Train Acc: 22.46%, Val Loss: 1.7884, Val Acc: 15.90%\n",
            "Epoch 8/10, Train Loss: 1.7869, Train Acc: 22.77%, Val Loss: 1.7969, Val Acc: 18.14%\n",
            "Epoch 9/10, Train Loss: 1.7876, Train Acc: 22.19%, Val Loss: 1.7925, Val Acc: 18.54%\n",
            "Epoch 10/10, Train Loss: 1.7882, Train Acc: 32.98%, Val Loss: 1.7883, Val Acc: 18.85%\n",
            "Training complete\n"
          ]
        }
      ]
    }
  ]
}